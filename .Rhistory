setwd("C:/Users/Owner/Desktop/Research/MachineLearningDataStructures")
rTrees <- read.delim("rdata.txt", header = F)
rTrees$V1 <- gsub(pattern = " ", replacement = "", rTrees$V1,fixed = TRUE)
rTrees <- data.frame(do.call('rbind', strsplit(as.character(rTrees$V1),',',fixed = T)))
rTrees$X1 <- as.numeric(as.character(rTrees$X1))
rTrees$X2 <- as.numeric(as.character(rTrees$X2))
nBayes <- read.delim("naiveBayesData.txt", header=F)
nBayes$V1 <- gsub(pattern = " ", replacement = "", nBayes$V1,fixed = TRUE)
nBayes <- data.frame(do.call('rbind', strsplit(as.character(nBayes$V1),',',fixed = T)))
nBayes$X1 <- as.numeric(as.character(nBayes$X1))
nBayes$X2 <- as.numeric(as.character(nBayes$X2))
nBayes <- nBayes[nBayes$X2 <.93,]
df <- read.csv("house-votes-84.data", header = FALSE)
names(df)[1] ="party"
names(df)[2] = "handicapped-infants"
names(df)[3] = "water-project"
names(df)[4] = "budget"
names(df)[5] =  "physician-fee-freeze"
names(df)[6] =  "el-salvador aid"
names(df)[7] =  "religion in schools"
names(df)[8] =  "anti-satellite"
names(df)[9] = "nicaraguan aid"
names(df)[10] = "missile"
names(df)[11] = "immigration"
names(df)[12] = "synfuel cutback"
names(df)[13] = "education"
names(df)[14] = "superfund"
names(df)[15] = "crime"
names(df)[16] = "duty free exports"
names(df)[17] = "south africa"
#setting up data from my tests for Regression Trees
rTrees <- read.delim("rdata.txt", header = F)
rTrees$V1 <- gsub(pattern = " ", replacement = "", rTrees$V1,fixed = TRUE)
rTrees <- data.frame(do.call('rbind', strsplit(as.character(rTrees$V1),',',fixed = T)))
rTrees$X1 <- as.numeric(as.character(rTrees$X1))
rTrees$X2 <- as.numeric(as.character(rTrees$X2))
plot((nBayes$X1),(nBayes$X2), main = "Naive Bayes Prediction Accuracy", xlab = "Ammount of Training data", ylab="Accuracy Percentage", ylim= c(.5,.95))
```
View(nBayes)
nfit <- nls((rTrees$X2) ~ a + b * (rTrees$X1)^(-c),nBays,start = list(a=80,b=20,c=0.2))
nfit <- nls((rTrees$X2) ~ a + b * (rTrees$X1)^(-c),nBayes,start = list(a=80,b=20,c=0.2))
nfit <- nls(y~a*x/(b+x))
x <- nBayes$X1
nfit <- nls((nBayes$X2)~a*x/(b+x))
x <- nBayes$X1
y <- nBayes$X2
nfit <- nls(y~a*x/(b+x))
plot((nBayes$X1),(nBayes$X2), main = "Naive Bayes Prediction Accuracy", xlab = "Ammount of Training data", ylab="Accuracy Percentage", ylim= c(.5,.95))
lines(x,predict(m), lty=2,col="red",lwd=3)
lines(x,predict(nfit), lty=2,col="red",lwd=3)
x<-rTrees$X1
y<-rTrees$X2
rLines <- nls(y~a*x/(b+x))
fullTree <- rpart(party~.,data = df, method = "class", control=rpart.control(minsplit=1, cp=0))
printcp(fullTree)
library(knitr)
library(rpart)
fullTree <- rpart(party~.,data = df, method = "class", control=rpart.control(minsplit=1, cp=0))
printcp(fullTree)
plot(fullTree, uniform=TRUE,main="Congress Regression Tree - Full Data")
text(fullTree, use.n=TRUE, all=TRUE, cex=.7)
halfdf <- df[1:217,]
halfTree <- rpart(party~.,data = halfdf, method = "class", control=rpart.control(minsplit=1, cp=0))
printcp(halfTree)
plot(halfTree, uniform=TRUE,main="Congress Regression Tree - Half Data")
text(halfTree, use.n=TRUE, all=TRUE, cex=.7)
xlab = "Ammount of Training data", ylab="Accuracy Percentage",ylim= c(.5,1))
lines(x,predict(rLines), lty=2,col="red",lwd=3)
plot((rTrees$X1),(rTrees$X2), type = "p", main = "Regression Tree Prediction Accuracy", xlab = "Ammount of Training data", ylab="Accuracy Percentage",ylim= c(.5,1))
lines(x,predict(rLines), lty=2,col="red",lwd=3)
