---
title: "Machine Learning Data Structures"
author: "Elizabeth Tigner"
date: "November 17, 2016"
output: html_document
---

```{r setup, include=FALSE}
library(knitr)

library(rpart)
#Setting up my visual for splitting
df <- read.csv("house-votes-84.data", header = FALSE)
names(df)[1] ="party"
names(df)[2] = "handicapped-infants"
names(df)[3] = "water-project"
names(df)[4] = "budget"
names(df)[5] =  "physician-fee-freeze"
names(df)[6] =  "el-salvador aid"
names(df)[7] =  "religion in schools"
names(df)[8] =  "anti-satellite"
names(df)[9] = "nicaraguan aid"
names(df)[10] = "missile"
names(df)[11] = "immigration"
names(df)[12] = "synfuel cutback"
names(df)[13] = "education"
names(df)[14] = "superfund"
names(df)[15] = "crime"
names(df)[16] = "duty free exports"
names(df)[17] = "south africa"

#setting up data from my tests for Regression Trees
rTrees <- read.delim("rdata.txt", header = F)
rTrees$V1 <- gsub(pattern = " ", replacement = "", rTrees$V1,fixed = TRUE)
rTrees <- data.frame(do.call('rbind', strsplit(as.character(rTrees$V1),',',fixed = T)))
rTrees$X1 <- as.numeric(as.character(rTrees$X1))
rTrees$X2 <- as.numeric(as.character(rTrees$X2))
```
This Project was to learn and make two simple machinelearning node prediction models. The two models I learned were Regression Trees and Naive Bayes. I wrote these programs in python. I then tested them using different k folds to test teh accuracy of the programs 


##Regression Tree Testing Results 
Here are my results from testing the Regression Tree program. The X axis is the amount of training data and the Y axis is the accuracy of the program

```{r, fig.width=8, fig.height=8}
plot((rTrees$X1),(rTrees$X2), type = "p", main = "Regression Tree Prediction Accuracy", 
     xlab = "Ammount of Training data", ylab="Accuracy Percentage")
```

##Regrssion Tree Visualization
Full Data Set
```{r, fig.width=13, fig.height=8}
fullTree <- rpart(party~.,data = df, method = "class", control=rpart.control(minsplit=1, cp=0))
printcp(fullTree)
plot(fullTree, uniform=TRUE,main="Congress Regression Tree - Full Data")
text(fullTree, use.n=TRUE, all=TRUE, cex=.7)
```
Half
```{r,fig.width=13, fig.height=8}
halfdf <- df[1:217,]
halfTree <- rpart(party~.,data = halfdf, method = "class", control=rpart.control(minsplit=1, cp=0))
printcp(halfTree)
plot(halfTree, uniform=TRUE,main="Congress Regression Tree - Half Data")
text(halfTree, use.n=TRUE, all=TRUE, cex=.7)
```

Forth
```{r,fig.width=13, fig.height=8}
forthdf <- df[1:108,]
forthTree <- rpart(party~.,data = forthdf, method = "class", control=rpart.control(minsplit=1, cp=0))
printcp(forthTree)
plot(forthTree, uniform=TRUE,main="Congress Regression Tree - Forth Data")
text(forthTree, use.n=TRUE, all=TRUE, cex=.7)
```

Eigth
```{r,fig.width=13, fig.height=8}
eighthdf <- df[1:254,]
eigthTree <- rpart(party~.,data = eighthdf, method = "class", control=rpart.control(minsplit=1, cp=0))
printcp(eigthTree)
plot(eigthTree, uniform=TRUE,main="Congress Regression Tree - Eigth Data")
text(eigthTree, use.n=TRUE, all=TRUE, cex=.7)
```

